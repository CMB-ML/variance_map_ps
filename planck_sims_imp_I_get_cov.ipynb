{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm  # For progress bars\n",
    "\n",
    "from handle_data import get_map_dtype, get_planck_obs_data, get_planck_noise_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"handle_data\")\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"/data/jim/CMB_Data/\"\n",
    "ASSETS_DIRECTORY = f\"{DATA_ROOT}/Assets/Planck/\"\n",
    "PLANCK_NOISE_DIR = f\"{DATA_ROOT}/Planck_Noise/\"\n",
    "\n",
    "DETECTORS = [30, 44, 70, 100, 143, 217, 353, 545, 857]\n",
    "N_PLANCK_SIMS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lmax_for_nside(nside):\n",
    "    \"\"\"Helper function: Max ell for a given nside; to be considered a parameter\"\"\"\n",
    "    return 3 * nside - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planck Sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = product(DETECTORS, range(N_PLANCK_SIMS))\n",
    "\n",
    "for det, sim_num in combos:\n",
    "    src_map_fn = get_planck_noise_data(detector=det, \n",
    "                                       assets_directory=ASSETS_DIRECTORY, \n",
    "                                       realization=sim_num, \n",
    "                                       progress=True)\n",
    "print(\"All maps acquired!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [23:19<00:00, 27.99s/it]\n"
     ]
    }
   ],
   "source": [
    "def get_ps_data(detector):\n",
    "    if detector in [30, 44, 70]:\n",
    "        nside = 1024\n",
    "    else:\n",
    "        nside = 2048\n",
    "    lmax = get_lmax_for_nside(nside)  # Defined above as 3*Nside-1\n",
    "    # Getting power spectra for 100 maps at 100 GHz takes ~50 minutes\n",
    "    src_cls = []\n",
    "    for i in tqdm(range(N_PLANCK_SIMS)):\n",
    "        src_map_fn = get_planck_noise_data(detector=detector, assets_directory=ASSETS_DIRECTORY, realization=i, progress=True)\n",
    "        t_src_map = hp.read_map(src_map_fn) * 1e6\n",
    "        src_cls.append(hp.anafast(t_src_map, lmax=lmax))\n",
    "\n",
    "    # Determine parameters for approximating the distribution\n",
    "\n",
    "    # Use log scaling for the power spectra; otherwise it's dominated by low ells\n",
    "    log_src_cls = np.log10(src_cls)\n",
    "\n",
    "    # We want to find the components that explain the majority of the variance\n",
    "    #   We don't have enough maps to fully determine the distribution, but a full\n",
    "    #   covariance matrix is overkill anyways. PCA gives a good, concise summary.\n",
    "    pca = PCA().fit(log_src_cls)\n",
    "\n",
    "    # We need the mean, the components (eigenvectors), and the variance (eigenvalues)\n",
    "    #   These are surrogates for the full covariance matrix\n",
    "    mean_ps = pca.mean_\n",
    "    components = pca.components_  \n",
    "    variance = pca.explained_variance_\n",
    "\n",
    "    # Save the results; delete the variables so we know we test loading them\n",
    "    np.savez(f\"noise_pca_{detector}GHz.npz\", mean=mean_ps, components=components, variance=variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for det in DETECTORS:\n",
    "    get_ps_data(det)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "var_map_demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
