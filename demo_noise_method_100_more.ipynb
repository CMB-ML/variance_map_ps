{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Many Filtered Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to generate many filtered maps at the same time to look at the population of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PLANCK_SIMS = 100\n",
    "N_OUTPUT_SIMS = 5\n",
    "NSIDE_OUTPUT  = 512\n",
    "DETECTOR      = 100\n",
    "WHT_SEED      = 42   # seed for the white noise sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate and Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "import pysm3.units as u\n",
    "\n",
    "from cmbml.utils.handle_data import (\n",
    "    get_planck_obs_data, \n",
    "    get_planck_noise_data, \n",
    "    # get_planck_hm_data, \n",
    "    get_map_dtype\n",
    "    )\n",
    "from cmbml.utils.fits_inspection import get_field_unit\n",
    "\n",
    "from system_config import ASSETS_DIRECTORY, PLANCK_NOISE_DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging was helpful when debugging my handle_data module\n",
    "logging.basicConfig(\n",
    "    level=logging.WARNING,  # If DEBUG, there's a bunch of PySM3 and Matplotlib stuff\n",
    "    format='%(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_many_ps(ps_s,\n",
    "            title=None, \n",
    "            x_low=0.7,\n",
    "            x_high=1e4,\n",
    "            y_low=1e-4,\n",
    "            y_high=1e-2,\n",
    "            styles=None,\n",
    "            labels=None,\n",
    "            white_noise_expected=None,\n",
    "            legend=True,\n",
    "            focus_first=False):\n",
    "    y_label=\"$N_{\\\\ell}$\" + f\"(unit)\"\n",
    "    x_label=\"$\\\\ell$\"\n",
    "    plt.figure()\n",
    "    for i, ps in enumerate(ps_s):\n",
    "        ells = np.arange(len(ps)).astype(float)\n",
    "        if x_low < 1:\n",
    "            ells[0] = x_low\n",
    "        style=None\n",
    "        linewidth=None\n",
    "        color=None\n",
    "        if styles is None:\n",
    "            pass\n",
    "        elif styles[i] != \"-\":\n",
    "            style = styles[i]\n",
    "            linewidth = 2\n",
    "        else:\n",
    "            style = styles[i]\n",
    "            linewidth = 1\n",
    "        if focus_first and i == 0:\n",
    "            color='black'\n",
    "            linewidth=3\n",
    "        label = None if labels is None else labels[i]\n",
    "        plt.plot(ells, ps, label=label, linestyle=style, color=color, linewidth=linewidth)\n",
    "    # if white_noise_expected is not None:\n",
    "    #     plt.axhline(y=white_noise_expected, color='black', linestyle='--', linewidth=1)\n",
    "    #     plt.text(y=white_noise_expected, x=x_high, s=\"$\\\\sigma_{\\\\ell}=\" + f\"{white_noise_expected:.1e}$\", \n",
    "    #              color='black',\n",
    "    #              horizontalalignment='right', verticalalignment='bottom')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.xlim([x_low-0.00001, x_high])\n",
    "    plt.ylim([y_low, y_high])\n",
    "    plt.title(title)\n",
    "    if legend:\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENTER_FREQS = {\n",
    "    30: 28.4 * u.GHz,      # Value from Planck DeltaBandpassTable & Planck 2018 I, Table 4\n",
    "    44: 44.1 * u.GHz,      # Value from Planck DeltaBandpassTable & Planck 2018 I, Table 4\n",
    "    70: 70.4 * u.GHz,      # Value from Planck DeltaBandpassTable & Planck 2018 I, Table 4\n",
    "    100: 100.89 * u.GHz,   # Value from Planck DeltaBandpassTable\n",
    "    143: 142.876 * u.GHz,  # Value from Planck DeltaBandpassTable\n",
    "    217: 221.156 * u.GHz,  # Value from Planck DeltaBandpassTable\n",
    "    353: 357.5 * u.GHz,    # Value from Planck DeltaBandpassTable\n",
    "    545: 555.2 * u.GHz,    # Value from Planck DeltaBandpassTable\n",
    "    857: 866.8 * u.GHz,    # Value from Planck DeltaBandpassTable\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xxcov_field_num(detector, field_str):\n",
    "    if detector not in [30, 44, 70, 100, 143, 217, 353, 545, 857]:\n",
    "        raise ValueError(f\"Detector {detector} not recognized\")\n",
    "    field_str = field_str.lower()\n",
    "    lower_field_nums = dict(ii=4, iq=5, iu=6, qq=7, qu=8, uu=9)\n",
    "    upper_field_nums = dict(ii=2)  # These detectors only have intensity data\n",
    "    if detector in [545, 857]:\n",
    "        if field_str not in upper_field_nums.keys():\n",
    "            raise ValueError(f\"Field {field_str} not available for detector {detector}\")\n",
    "        res = upper_field_nums[field_str]\n",
    "    else:\n",
    "        if field_str not in ['ii', 'iq', 'iu', 'qq', 'qu', 'uu']:\n",
    "            raise ValueError(f\"Field {field_str} not available for detector {detector}\")\n",
    "        res = lower_field_nums[field_str]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _change_variance_map_resolution(m, nside_out):\n",
    "    # For variance maps, because statistics\n",
    "    power = 2\n",
    "\n",
    "    # From PySM3 template.py's read_map function, with minimal alteration (added 'power'):\n",
    "    m_dtype = get_map_dtype(m)\n",
    "    nside_in = hp.get_nside(m)\n",
    "    if nside_out < nside_in:  # do downgrading in double precision, per healpy instructions\n",
    "        m = hp.ud_grade(m.astype(np.float64), power=power, nside_out=nside_out)\n",
    "    elif nside_out > nside_in:\n",
    "        m = hp.ud_grade(m, power=power, nside_out=nside_out)\n",
    "    m = m.astype(m_dtype, copy=False)\n",
    "    # End of used portion\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_field_str_to_Unit(unit_str):\n",
    "    custom_units = {\n",
    "            # 'uK_CMB': u.uK_CMB,\n",
    "            'Kcmb': u.K_CMB,\n",
    "            # 'K_CMB': u.K_CMB,\n",
    "            'MJy/sr': u.MJy / u.sr,\n",
    "            'Kcmb^2': u.K_CMB**2,\n",
    "            '(K_CMB)^2': u.K_CMB**2,\n",
    "            # 'K_CMB^2': u.K_CMB**2,\n",
    "            # 'uK_CMB^2': u.uK_CMB**2,\n",
    "            # '(uK_CMB)^2': u.uK_CMB**2,\n",
    "            # '(MJy/sr)^2': (u.MJy / u.sr)**2,\n",
    "            '(Mjy/sr)^2': (u.MJy / u.sr)**2,\n",
    "            # 'MJy/sr^2': (u.MJy / u.sr)**2\n",
    "        }\n",
    "    if not isinstance(unit_str, str):\n",
    "        try:\n",
    "            unit_str = unit_str.item()\n",
    "        except AttributeError:\n",
    "            raise TypeError(f\"Expected a string, but got {type(unit_str)}\")\n",
    "\n",
    "    try:\n",
    "        # Attempt to parse with Astropy's Unit function\n",
    "        return u.Unit(unit_str)\n",
    "    except ValueError:  # Astropy throws a ValueError for unrecognized units\n",
    "        if unit_str in custom_units.keys():\n",
    "            return custom_units[unit_str]\n",
    "        else:\n",
    "            raise ValueError(f\"Unit {unit_str} not recognized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scale_map(det, nside_out):\n",
    "    obs_fn = get_planck_obs_data(detector=det, assets_directory=ASSETS_DIRECTORY)\n",
    "    use_field = get_xxcov_field_num(det, 'II')\n",
    "    II_cov_map = hp.read_map(obs_fn, hdu=1, field=use_field)\n",
    "    II_cov_map_512 = _change_variance_map_resolution(II_cov_map, nside_out)\n",
    "    scale_map = np.sqrt(II_cov_map_512)\n",
    "\n",
    "    var_map_unit = get_field_unit(obs_fn, hdu=1, field_idx=use_field)\n",
    "    var_map_unit = convert_field_str_to_Unit(var_map_unit)\n",
    "    scale_map_unit = var_map_unit**0.5\n",
    "    scale_map = u.Quantity(scale_map, unit=scale_map_unit)\n",
    "\n",
    "    return scale_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_cls_from_pca_results(n_sims, src_mean_ps, src_variance, src_components):\n",
    "    num_components = len(src_variance)\n",
    "\n",
    "    std_devs = np.sqrt(src_variance)\n",
    "\n",
    "    if n_sims == 1:\n",
    "        reduced_shape = (num_components,)\n",
    "    else:\n",
    "        reduced_shape = (n_sims, num_components)\n",
    "\n",
    "    reduced_samples = np.random.normal(0, std_devs, reduced_shape)\n",
    "    # Reconstruct power spectra in log10 space\n",
    "    tgt_log_ps = reduced_samples @ src_components + src_mean_ps\n",
    "    # Convert out of log10 space\n",
    "    tgt_cls = 10**tgt_log_ps\n",
    "    return tgt_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tgt_noise_params_from_det_file(det, n_sims):\n",
    "    data = np.load(f\"noise_models2/noise_model_{det}GHz.npz\")\n",
    "\n",
    "    src_mean_ps     = data['mean_ps']\n",
    "    src_components  = data['components']\n",
    "    src_variance    = data['variance']\n",
    "\n",
    "    # src_mean_maps   = data['maps_mean']\n",
    "    # src_sd_maps     = data['maps_sd']\n",
    "\n",
    "    src_map_unit    = data['maps_unit'].item()\n",
    "\n",
    "    src_map_unit = convert_field_str_to_Unit(src_map_unit)\n",
    "\n",
    "    tgt_cls = get_target_cls_from_pca_results(n_sims, src_mean_ps, src_variance, src_components)\n",
    "\n",
    "    return tgt_cls, src_map_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downgrade_map_via_alm(some_map, target_nside):\n",
    "    try:\n",
    "        map_unit = some_map.unit\n",
    "    except AttributeError:\n",
    "        map_unit = None\n",
    "    source_nside = hp.get_nside(some_map)\n",
    "    assert target_nside <= source_nside/2, \"Target nside must be less than the source nside\"\n",
    "    lmax_source = 3 * source_nside - 1\n",
    "    alm = hp.map2alm(some_map, lmax=lmax_source)\n",
    "\n",
    "    lmax_target = int(3 * target_nside - 1)\n",
    "    alm_filter = np.zeros(lmax_source+1)\n",
    "    alm_filter[:lmax_target+1] = 1\n",
    "    alm_filtered = hp.almxfl(alm, alm_filter)\n",
    "    some_map_filtered = hp.alm2map(alm_filtered, nside=target_nside)\n",
    "    if map_unit is not None:\n",
    "        some_map_filtered = u.Quantity(some_map_filtered, unit=map_unit)\n",
    "    return some_map_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map_with_unit(fn):\n",
    "    map_ = hp.read_map(fn)\n",
    "    map_units = get_field_unit(fn, hdu=1, field_idx=0)\n",
    "    map_units = convert_field_str_to_Unit(map_units)\n",
    "    return map_ * map_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_map(detector, nside_out):\n",
    "    fn = f\"noise_avgs/avg_noise_map_{detector}_TQU_100.fits\"\n",
    "    planck_nse_avg = get_map_with_unit(fn)\n",
    "    if hp.get_nside(planck_nse_avg) != nside_out:\n",
    "        planck_nse_avg = downgrade_map_via_alm(planck_nse_avg, nside_out)\n",
    "    return planck_nse_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lmax_for_nside(nside):\n",
    "    \"\"\"Helper function: Max ell for a given nside; to be considered a parameter\"\"\"\n",
    "    return 3 * nside - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autopower(map_, mask, lmax):\n",
    "    return get_xpower(map1=map_, map2=None, mask=mask, lmax=lmax)\n",
    "\n",
    "def get_xpower(map1, map2, mask, lmax, use_pixel_weights=False):\n",
    "    if mask is None:\n",
    "        ps = hp.anafast(map1, map2, lmax=lmax, use_pixel_weights=use_pixel_weights)\n",
    "    else:\n",
    "        mean1 = np.sum(map1*mask)/np.sum(mask)\n",
    "        input1 = mask*(map1-mean1)\n",
    "        if map2 is None:\n",
    "            input2 = None\n",
    "        else:\n",
    "            mean2 = np.sum(map2*mask)/np.sum(mask)\n",
    "            input2 = mask*(map2-mean2)\n",
    "        fsky = np.sum(mask)/mask.shape[0]\n",
    "        ps = hp.anafast(input1,\n",
    "                        input2,\n",
    "                        lmax=lmax,\n",
    "                        use_pixel_weights=use_pixel_weights)\n",
    "        ps = ps / fsky\n",
    "    return ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask(nside, width=10):\n",
    "    mask = np.ones(hp.nside2npix(nside))\n",
    "    mask[hp.query_strip(nside, np.radians(90 - width/2), np.radians(90 + width /2))] = 0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_1024 = make_mask(1024)\n",
    "mask_1024_sm1 = hp.smoothing(mask_1024, fwhm=np.radians(1))\n",
    "mask_2048 = make_mask(2048)\n",
    "mask_2048_sm1 = hp.smoothing(mask_2048, fwhm=np.radians(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sims(detector):\n",
    "    nside = 1024 if detector in [30, 44, 70] else 2048\n",
    "\n",
    "    lmax = get_lmax_for_nside(nside)\n",
    "    src_cls = []\n",
    "    src_maps_means = []  # Not to be used in the model\n",
    "\n",
    "    mask_sm1 = mask_1024_sm1 if nside == 1024 else mask_2048_sm1\n",
    "\n",
    "    avg_map = get_avg_map(detector, nside)\n",
    "\n",
    "    for i in tqdm(range(N_PLANCK_SIMS)):\n",
    "        src_map_fn = get_planck_noise_data(detector=detector, assets_directory=PLANCK_NOISE_DIRECTORY, realization=i)\n",
    "        t_src_map = get_map_with_unit(src_map_fn)\n",
    "\n",
    "        t_src_map = t_src_map - avg_map\n",
    "\n",
    "        t_cl = get_autopower(t_src_map, mask_sm1, lmax)\n",
    "\n",
    "        if i == 0:\n",
    "            src_map_unit = get_field_unit(src_map_fn, hdu=1, field_idx=0)\n",
    "            src_map_unit = convert_field_str_to_Unit(src_map_unit)\n",
    "\n",
    "        src_cls.append(t_cl)\n",
    "        src_map_mean = np.sum(t_src_map * mask_sm1) / np.sum(mask_sm1)\n",
    "        src_maps_means.append(src_map_mean)\n",
    "\n",
    "    return src_cls, src_maps_means, src_map_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pca(src_cls):\n",
    "    log_src_cls = np.log10(src_cls)\n",
    "\n",
    "    pca = PCA().fit(log_src_cls)\n",
    "    mean_ps = pca.mean_\n",
    "    components = pca.components_\n",
    "    variance = pca.explained_variance_\n",
    "    return mean_ps, components, variance\n",
    "\n",
    "def make_mean_sd(src_maps_means):\n",
    "    t = np.array([x.value for x in src_maps_means])\n",
    "    maps_mean = np.mean(t) * src_maps_means[0].unit\n",
    "    maps_sd = np.std(t) * src_maps_means[0].unit\n",
    "    return maps_mean, maps_sd\n",
    "\n",
    "def save_noise_model(detector, mean_ps, components, variance, maps_mean, maps_sd, src_map_unit):\n",
    "    np.savez(f\"noise_models/noise_model_{detector}GHz.npz\",\n",
    "             mean_ps=mean_ps,\n",
    "             components=components,\n",
    "             variance=variance,\n",
    "             maps_mean=maps_mean,\n",
    "             maps_sd=maps_sd,\n",
    "             maps_unit=src_map_unit)\n",
    "\n",
    "def save_noise_details(detector, \n",
    "                       src_cls, \n",
    "                       src_maps_means, \n",
    "                       src_map_unit\n",
    "                       ):\n",
    "    src_maps_means = np.array([x.value for x in src_maps_means])\n",
    "    print(f\"Saving noise model details for {detector}GHz\")\n",
    "    np.savez(f\"noise_model_details/noise_model_detail_{detector}GHz.npz\",\n",
    "             src_cls=src_cls,\n",
    "             src_maps_means=src_maps_means,\n",
    "             maps_unit=src_map_unit\n",
    "             )\n",
    "\n",
    "def make_noise_model(detector):\n",
    "    src_cls, src_maps_means, src_map_unit = parse_sims(detector)\n",
    "    mean_ps, components, variance = make_pca(src_cls)\n",
    "    maps_mean, maps_sd = make_mean_sd(src_maps_means)\n",
    "\n",
    "    save_noise_details(detector=detector,\n",
    "                       src_cls=src_cls, \n",
    "                       src_maps_means=src_maps_means, \n",
    "                       src_map_unit=src_map_unit\n",
    "                       )\n",
    "\n",
    "    save_noise_model(detector=detector, \n",
    "                     mean_ps=mean_ps, \n",
    "                     components=components, \n",
    "                     variance=variance, \n",
    "                     maps_mean=maps_mean, \n",
    "                     maps_sd=maps_sd, \n",
    "                     src_map_unit=src_map_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Demo\n",
    "# DETECTOR = DETECTOR\n",
    "# _min_max = dict(min=-0.00002, max=0.00002)\n",
    "# _demo_map_fn = get_planck_noise_data(detector=DETECTOR, assets_directory=PLANCK_NOISE_DIRECTORY, realization=0)\n",
    "# _demo_map = get_map_with_unit(_demo_map_fn)\n",
    "\n",
    "# _demo_nside = hp.get_nside(_demo_map)\n",
    "# _demo_in_mask = make_mask(_demo_nside)\n",
    "\n",
    "# _demo_avg_map = get_avg_map(DETECTOR, _demo_nside)\n",
    "\n",
    "# _map_to_show = _demo_map - _demo_avg_map\n",
    "# _map_to_show = hp.ma(_map_to_show)\n",
    "# _map_to_show.mask = np.logical_not(_demo_in_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [51:01<00:00, 30.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving noise model details for 100GHz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "make_noise_model(DETECTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp.mollview(_demo_map, title=\"Demo map\", **_min_max)\n",
    "# hp.mollview(_demo_avg_map, title=\"Demo average map\", **_min_max)\n",
    "# hp.mollview(_map_to_show, title=\"Demo map - average map\", **_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _src_cls, _src_maps_means, _src_map_unit = parse_sims(_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _mean_ps, _components, _variance = make_pca(_src_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_rng = np.random.default_rng(seed=WHT_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tgt_cls, _src_map_unit = make_tgt_noise_params_from_det_file(DETECTOR, N_OUTPUT_SIMS)\n",
    "_tgt_cls = _tgt_cls * _src_map_unit**2\n",
    "\n",
    "_lmax = get_lmax_for_nside(NSIDE_OUTPUT)\n",
    "_scale_map = get_scale_map(DETECTOR, NSIDE_OUTPUT)\n",
    "_wht_nse_maps = _rng.normal(size=(N_OUTPUT_SIMS, _scale_map.size)) * _scale_map\n",
    "\n",
    "_output_sized_avg_map = get_avg_map(DETECTOR, NSIDE_OUTPUT)\n",
    "\n",
    "assert _src_map_unit == _scale_map.unit, \"Units do not match!\"\n",
    "\n",
    "_output_maps = []\n",
    "for i in range(N_OUTPUT_SIMS):\n",
    "    _wht_nse_alms  = hp.map2alm(_wht_nse_maps[i], lmax=_lmax)\n",
    "    _wht_nse_cl    = hp.alm2cl(_wht_nse_alms) * _wht_nse_maps.unit**2\n",
    "    _map_filter    = np.sqrt(_tgt_cls[i][:_lmax+1] / _wht_nse_cl)\n",
    "\n",
    "    # Filter map\n",
    "    _filtered_alms = hp.almxfl(_wht_nse_alms, _map_filter)\n",
    "    _output_map_nonstat  = hp.alm2map(_filtered_alms, nside=NSIDE_OUTPUT) * _src_map_unit\n",
    "\n",
    "    # Remove the monopole\n",
    "    # Should I instead use hp.remove_dipole()?\n",
    "    _output_map_nonstat -= _output_map_nonstat.mean()\n",
    "\n",
    "    # Add stationary noise for 353, 547, 857 GHz\n",
    "    _output_map = _output_map_nonstat + _output_sized_avg_map\n",
    "    _output_maps.append(_output_map)\n",
    "    del _wht_nse_alms, _wht_nse_cl, _map_filter, _filtered_alms, _output_map_nonstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_min_max = dict(min=-0.0002, max=0.0002)\n",
    "for m in _output_maps:\n",
    "    hp.mollview(m, **_min_max)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_demo_out_mask = make_mask(NSIDE_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_output_cls = []\n",
    "for m in _output_maps:\n",
    "    _output_cls.append(get_autopower(m, _demo_out_mask, _lmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_many_ps(_output_cls, \n",
    "             labels=[f\"Sim {i}\" for i in range(N_OUTPUT_SIMS)],\n",
    "             title=\"Output power spectra\", \n",
    "             x_low=0.7, x_high=1e4, \n",
    "             y_low=1e-15, y_high=None,\n",
    "             legend=False, \n",
    "             focus_first=False\n",
    "             )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmb-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
